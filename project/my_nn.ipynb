{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "from typing import Callable\n",
    "import skimage\n",
    "from skimage.color import rgb2hsv\n",
    "from skimage import io, util\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path\n",
    "path0 = os.path.join(\"cropped_0.jpg\")\n",
    "path1 = os.path.join(\"cropped_1.jpg\")\n",
    "path2 = os.path.join(\"cropped_2.jpg\")\n",
    "\n",
    "\n",
    "# Check if folder and image exist\n",
    "assert os.path.exists(path0), \"Image not found, please check directory structure\"\n",
    "assert os.path.exists(path1), \"Image not found, please check directory structure\"\n",
    "assert os.path.exists(path2), \"Image not found, please check directory structure\"\n",
    "\n",
    "# Load image\n",
    "image_0= np.array(Image.open(path0))\n",
    "image_1= np.array(Image.open(path1))\n",
    "image_2= np.array(Image.open(path2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Define the path to your dataset folder\n",
    "data_dir = 'my_dataset'\n",
    "\n",
    "# Step 2: Define Transforms (Optional)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),  # Resize images to a fixed size if needed\n",
    "    transforms.ToTensor(),           # Convert PIL image to tensor\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize images\n",
    "])\n",
    "\n",
    "# Step 3: Create Dataset Object\n",
    "dataset = ImageFolder(root=data_dir, transform=transform)\n",
    "\n",
    "# Step 4: Instantiate DataLoader\n",
    "batch_size = 64\n",
    "shuffle = True  # Shuffle data during training\n",
    "num_workers = 4  # Number of subprocesses to use for data loading\n",
    "trainloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0\n",
      "loss:  1.0993071794509888\n",
      "epoch  1\n",
      "loss:  1.072140097618103\n",
      "epoch  2\n",
      "loss:  1.0511088371276855\n",
      "epoch  3\n",
      "loss:  1.0021594762802124\n",
      "epoch  4\n",
      "loss:  0.9325926303863525\n",
      "epoch  5\n",
      "loss:  0.8590817451477051\n",
      "epoch  6\n",
      "loss:  0.7609049677848816\n",
      "epoch  7\n",
      "loss:  0.6482694745063782\n",
      "epoch  8\n",
      "loss:  0.5408826470375061\n",
      "epoch  9\n",
      "loss:  0.4241959750652313\n",
      "epoch  10\n",
      "loss:  0.31729331612586975\n",
      "epoch  11\n",
      "loss:  0.22149424254894257\n",
      "epoch  12\n",
      "loss:  0.1475239247083664\n",
      "epoch  13\n",
      "loss:  0.09607163816690445\n",
      "epoch  14\n",
      "loss:  0.0617181695997715\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        # self.pool = nn.MaxPool2d(2, 2)\n",
    "        # self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc1 = nn.Linear(128*128*3, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = self.pool(F.relu(self.conv1(x)))\n",
    "        # x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.005, momentum=0.9)\n",
    "\n",
    "epochs = 15\n",
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "    print(\"epoch \", epoch)\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        print(\"loss: \", loss.item())\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted labels:  tensor([1, 2, 0])\n",
      "true labels:  tensor([1, 2, 0])\n",
      "accuracy:  tensor(100.) %\n"
     ]
    }
   ],
   "source": [
    "#checking the labels\n",
    "\n",
    "for batch_idx, (images, labels) in enumerate(trainloader):\n",
    "    # for i in range(len(images)):\n",
    "    outputs = net.forward(images)\n",
    "    loss = criterion(outputs, labels)\n",
    "    predictions = torch.argmax(outputs, dim=1)\n",
    "    print(\"predicted labels: \", predictions)\n",
    "    print(\"true labels: \", labels)\n",
    "    num_points = len(labels)\n",
    "    correct =sum(predictions == labels)\n",
    "    accuracy = correct / num_points * 100\n",
    "    print(\"accuracy: \", accuracy, \"%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
